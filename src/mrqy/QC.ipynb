{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1696080684363,
     "user": {
      "displayName": "vani sri",
      "userId": "04310237964180536629"
     },
     "user_tz": -330
    },
    "id": "-VJuA7U7SOCd"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d as conv2\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import convex_hull_image,convex_hull_object\n",
    "from skimage import exposure as ex\n",
    "from skimage.filters import median\n",
    "from skimage.morphology import square\n",
    "# from skimage.util import pad   pad is not available in skimage==0.19.2\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import scipy\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class BaseVolume_dicom(dict):\n",
    "\n",
    "    def __init__(self, fname_outdir, v, ol,folder_foregrounds, sample_size, ch_flag):\n",
    "        dict.__init__(self)\n",
    "\n",
    "        self[\"warnings\"] = []\n",
    "        self[\"output\"] = []\n",
    "        self.addToPrintList(\"Patient\", v[1]['ID'], v, ol, 170)\n",
    "        self[\"outdir\"] = fname_outdir\n",
    "        self.addToPrintList(\"Name of Images\", os.listdir(fname_outdir + os.sep + v[1]['ID']), v, ol, 100)\n",
    "        for i,j in enumerate(v[1]):\n",
    "            if i != 0:\n",
    "                self.addToPrintList(j, v[1][j], v, ol, i)\n",
    "        # self.addToPrintList(\"MFR\", v[1]['Manufacturer'], v, ol, 1)\n",
    "        # self.addToPrintList(\"MFS\", v[1]['MFS'], v, ol, 2)\n",
    "        # self.addToPrintList(\"VRX\", v[1]['VR_x'], v, ol, 3)\n",
    "        # self.addToPrintList(\"VRY\", v[1]['VR_y'], v, ol, 4)\n",
    "        # self.addToPrintList(\"VRZ\", v[1]['VR_z'], v, ol, 5)\n",
    "        # self.addToPrintList(\"ROWS\", v[1]['Rows'], v, ol, 6)\n",
    "        # self.addToPrintList(\"COLS\", v[1]['Columns'], v, ol, 7)\n",
    "        # self.addToPrintList(\"TR\", v[1]['TR'], v, ol, 8)\n",
    "        # self.addToPrintList(\"TE\", v[1]['TE'], v, ol, 9)\n",
    "        self[\"os_handle\"] = v[0]\n",
    "        # self.addToPrintList(\"NUM\", v[1]['Number'], v, ol, 10)\n",
    "        self.addToPrintList(\"MEAN\", vol(v, sample_size, \"Mean\",folder_foregrounds, ch_flag), v, ol, 11)\n",
    "        self.addToPrintList(\"RNG\", vol(v, sample_size, \"Range\",folder_foregrounds, ch_flag), v, ol, 12)\n",
    "        self.addToPrintList(\"VAR\", vol(v, sample_size, \"Variance\",folder_foregrounds, ch_flag), v, ol, 13)\n",
    "        self.addToPrintList(\"CV\", vol(v, sample_size, \"CV\",folder_foregrounds, ch_flag), v, ol, 14)\n",
    "        self.addToPrintList(\"CPP\", vol(v, sample_size, \"CPP\",folder_foregrounds, ch_flag), v, ol, 15)\n",
    "        self.addToPrintList(\"PSNR\", vol(v, sample_size, \"PSNR\",folder_foregrounds, ch_flag), v, ol, 16)\n",
    "        self.addToPrintList(\"SNR1\", vol(v, sample_size, \"SNR1\",folder_foregrounds, ch_flag), v, ol, 17)\n",
    "        self.addToPrintList(\"SNR2\", vol(v, sample_size, \"SNR2\",folder_foregrounds, ch_flag), v, ol, 18)\n",
    "        self.addToPrintList(\"SNR3\", vol(v, sample_size, \"SNR3\",folder_foregrounds, ch_flag), v, ol, 19)\n",
    "        self.addToPrintList(\"SNR4\", vol(v, sample_size, \"SNR4\",folder_foregrounds, ch_flag), v, ol, 20)\n",
    "        self.addToPrintList(\"CNR\", vol(v, sample_size, \"CNR\",folder_foregrounds, ch_flag), v, ol, 21)\n",
    "        self.addToPrintList(\"CVP\", vol(v, sample_size, \"CVP\",folder_foregrounds, ch_flag), v, ol, 22)\n",
    "        self.addToPrintList(\"CJV\", vol(v, sample_size, \"CJV\",folder_foregrounds, ch_flag), v, ol, 23)\n",
    "        self.addToPrintList(\"EFC\", vol(v, sample_size, \"EFC\",folder_foregrounds, ch_flag), v, ol, 24)\n",
    "        self.addToPrintList(\"FBER\", vol(v, sample_size, \"FBER\",folder_foregrounds, ch_flag), v, ol, 25)\n",
    "\n",
    "    def addToPrintList(self, name, val, v, ol, il):\n",
    "        self[name] = val\n",
    "        self[\"output\"].append(name)\n",
    "        if name != 'Name of Images' and il != 170:\n",
    "            print('%s-%s. The %s of the patient with the name of <%s> is %s' % (ol,il,name, v[1]['ID'], val))\n",
    "\n",
    "\n",
    "class BaseVolume_nondicom(dict):\n",
    "\n",
    "    def __init__(self, fname_outdir, v, ol, sample_size, ch_flag):\n",
    "        dict.__init__(self)\n",
    "\n",
    "        self[\"warnings\"] = []\n",
    "        self[\"output\"] = []\n",
    "        self.addToPrintList(\"Patient\", v[1], v, ol, 170)\n",
    "        self[\"outdir\"] = fname_outdir\n",
    "        self.addToPrintList(\"Name of Images\", os.listdir(fname_outdir + os.sep + v[1]), v, ol, 100)\n",
    "        self.addToPrintList(\"VRX\", format(v[2].get_voxel_spacing()[0], '.2f'), v, ol, 1)\n",
    "        self.addToPrintList(\"VRY\", format(v[2].get_voxel_spacing()[1], '.2f'), v, ol, 2)\n",
    "        self.addToPrintList(\"VRZ\", format(v[2].get_voxel_spacing()[2], '.2f'), v, ol, 3)\n",
    "        self.addToPrintList(\"ROWS\", np.shape(v[0])[1], v, ol, 4)\n",
    "        self.addToPrintList(\"COLS\", np.shape(v[0])[2], v, ol, 5)\n",
    "        self[\"os_handle\"] = v[0]\n",
    "        self.addToPrintList(\"NUM\", len(v[0]), v, ol, 6)\n",
    "        self.addToPrintList(\"MEAN\", vol(v, sample_size, \"Mean\",fname_outdir, ch_flag), v, ol, 7)\n",
    "        self.addToPrintList(\"RNG\", vol(v, sample_size, \"Range\",fname_outdir, ch_flag), v, ol, 8)\n",
    "        self.addToPrintList(\"VAR\", vol(v, sample_size, \"Variance\",fname_outdir, ch_flag), v, ol, 9)\n",
    "        self.addToPrintList(\"CV\", vol(v, sample_size, \"CV\",fname_outdir, ch_flag), v, ol, 10)\n",
    "        self.addToPrintList(\"CPP\", vol(v, sample_size, \"CPP\",fname_outdir, ch_flag), v, ol, 11)\n",
    "        self.addToPrintList(\"PSNR\", vol(v, sample_size, \"PSNR\",fname_outdir, ch_flag), v, ol, 12)\n",
    "        self.addToPrintList(\"SNR1\", vol(v, sample_size, \"SNR1\",fname_outdir, ch_flag), v, ol, 13)\n",
    "        self.addToPrintList(\"SNR2\", vol(v, sample_size, \"SNR2\",fname_outdir, ch_flag), v, ol, 14)\n",
    "        self.addToPrintList(\"SNR3\", vol(v, sample_size, \"SNR3\",fname_outdir, ch_flag), v, ol, 15)\n",
    "        self.addToPrintList(\"SNR4\", vol(v, sample_size, \"SNR4\",fname_outdir, ch_flag), v, ol, 16)\n",
    "        self.addToPrintList(\"CNR\", vol(v, sample_size, \"CNR\",fname_outdir, ch_flag), v, ol, 17)\n",
    "        self.addToPrintList(\"CVP\", vol(v, sample_size, \"CVP\",fname_outdir, ch_flag), v, ol, 18)\n",
    "        self.addToPrintList(\"CJV\", vol(v, sample_size, \"CJV\",fname_outdir, ch_flag), v, ol, 19)\n",
    "        self.addToPrintList(\"EFC\", vol(v, sample_size, \"EFC\",fname_outdir, ch_flag), v, ol, 20)\n",
    "        self.addToPrintList(\"FBER\", vol(v, sample_size, \"FBER\",fname_outdir, ch_flag), v, ol, 21)\n",
    "\n",
    "    def addToPrintList(self, name, val, v, ol, il):\n",
    "        self[name] = val\n",
    "        self[\"output\"].append(name)\n",
    "        if name != 'Name of Images' and il != 170:\n",
    "            print('%s-%s. The %s of the patient with the name of <%s> is %s' % (ol,il,name, v[1], val))\n",
    "\n",
    "\n",
    "class BaseVolume_mat(dict):\n",
    "\n",
    "    def __init__(self, fname_outdir, v, ol,folder_foregrounds, sample_size):\n",
    "        dict.__init__(self)\n",
    "\n",
    "        self[\"warnings\"] = []\n",
    "        self[\"output\"] = []\n",
    "        self.addToPrintList(\"Patient\", v[1]['ID'], v, ol, 170)\n",
    "        self[\"outdir\"] = fname_outdir\n",
    "        self.addToPrintList(\"Name of Images\", os.listdir(fname_outdir + os.sep + v[1]['ID']), v, ol, 100)\n",
    "        self.addToPrintList(\"ROWS\", np.shape(v[0])[0], v, ol, 1)\n",
    "        self.addToPrintList(\"COLS\", np.shape(v[0])[1], v, ol, 2)\n",
    "        self[\"os_handle\"] = v[0]\n",
    "        self.addToPrintList(\"NUM\", np.shape(v[0])[2], v, ol, 3)\n",
    "        self.addToPrintList(\"MEAN\", vol(v, sample_size, \"Mean\",folder_foregrounds), v, ol, 4)\n",
    "        self.addToPrintList(\"RNG\", vol(v, sample_size, \"Range\",folder_foregrounds), v, ol, 5)\n",
    "        self.addToPrintList(\"VAR\", vol(v, sample_size, \"Variance\",folder_foregrounds), v, ol, 6)\n",
    "        self.addToPrintList(\"CV\", vol(v, sample_size, \"CV\",folder_foregrounds), v, ol, 7)\n",
    "        self.addToPrintList(\"CPP\", vol(v, sample_size, \"CPP\",folder_foregrounds), v, ol, 8)\n",
    "        self.addToPrintList(\"PSNR\", vol(v, sample_size, \"PSNR\",folder_foregrounds), v, ol, 9)\n",
    "        self.addToPrintList(\"SNR1\", vol(v, sample_size, \"SNR1\",folder_foregrounds), v, ol, 10)\n",
    "        self.addToPrintList(\"SNR2\", vol(v, sample_size, \"SNR2\",folder_foregrounds), v, ol, 11)\n",
    "        self.addToPrintList(\"SNR3\", vol(v, sample_size, \"SNR3\",folder_foregrounds), v, ol, 12)\n",
    "        self.addToPrintList(\"SNR4\", vol(v, sample_size, \"SNR4\",folder_foregrounds), v, ol, 13)\n",
    "        self.addToPrintList(\"CNR\", vol(v, sample_size, \"CNR\",folder_foregrounds), v, ol, 14)\n",
    "        self.addToPrintList(\"CVP\", vol(v, sample_size, \"CVP\",folder_foregrounds), v, ol, 15)\n",
    "        self.addToPrintList(\"CJV\", vol(v, sample_size, \"CJV\",folder_foregrounds), v, ol, 16)\n",
    "        self.addToPrintList(\"EFC\", vol(v, sample_size, \"EFC\",folder_foregrounds), v, ol, 17)\n",
    "        self.addToPrintList(\"FBER\", vol(v, sample_size, \"FBER\",folder_foregrounds), v, ol, 18)\n",
    "\n",
    "    def addToPrintList(self, name, val, v, ol, il):\n",
    "        self[name] = val\n",
    "        self[\"output\"].append(name)\n",
    "        if name != 'Name of Images' and il != 170:\n",
    "            print('%s-%s. The %s of the patient with the name of <%s> is %s' % (ol,il,name, v[1]['ID'], val))\n",
    "\n",
    "def vol(v, sample_size, kk, outi_folder, ch_flag):\n",
    "    switcher={\n",
    "            'Mean': mean,\n",
    "            'Range': rang,\n",
    "            'Variance': variance,\n",
    "            'CV': percent_coefficient_variation,\n",
    "            'CPP': contrast_per_pixle,\n",
    "            'PSNR': fpsnr,\n",
    "            'SNR1': snr1,\n",
    "            'SNR2': snr2,\n",
    "            'SNR3': snr3,\n",
    "            'SNR4': snr4,\n",
    "            'CNR': cnr,\n",
    "            'CVP': cvp,\n",
    "            'CJV': cjv,\n",
    "            'EFC': efc,\n",
    "            'FBER': fber,\n",
    "            }\n",
    "    func=switcher.get(kk)\n",
    "    M = []\n",
    "    for i in range(1, len(v[0]), sample_size):\n",
    "        I = v[0][i]\n",
    "#        I = I - np.min(I)  # for CT\n",
    "        F, B, c, f, b = foreground(I,outi_folder,v,i)\n",
    "        if np.std(F) == 0:  # whole zero slice, no measure computing\n",
    "            continue\n",
    "        measure = func(F, B, c, f, b)\n",
    "        if np.isnan(measure) or np.isinf(measure):\n",
    "            continue\n",
    "            # measure = 0\n",
    "        # To do (add something)\n",
    "        M.append(measure)\n",
    "    return np.mean(M)\n",
    "\n",
    "\n",
    "\n",
    "def foreground(img,save_folder,v,inumber):\n",
    "    try:\n",
    "        h = ex.equalize_hist(img[:,:])*255\n",
    "        oi = np.zeros_like(img, dtype=np.uint16)\n",
    "        oi[(img > threshold_otsu(img)) == True] = 1\n",
    "        oh = np.zeros_like(img, dtype=np.uint16)\n",
    "        oh[(h > threshold_otsu(h)) == True] = 1\n",
    "        nm = img.shape[0] * img.shape[1]\n",
    "        w1 = np.sum(oi)/(nm)\n",
    "        w2 = np.sum(oh)/(nm)\n",
    "        ots = np.zeros_like(img, dtype=np.uint16)\n",
    "        new =( w1 * img) + (w2 * h)\n",
    "        ots[(new > threshold_otsu(new)) == True] = 1\n",
    "        conv_hull = convex_hull_image(ots)\n",
    "        conv_hull = convex_hull_image(ots)\n",
    "        ch = np.multiply(conv_hull, 1)\n",
    "        fore_image = ch * img\n",
    "        back_image = (1 - ch) * img\n",
    "    except Exception:\n",
    "        fore_image = img.copy()\n",
    "        back_image = np.zeros_like(img, dtype=np.uint16)\n",
    "        conv_hull = np.zeros_like(img, dtype=np.uint16)\n",
    "        ch = np.multiply(conv_hull, 1)\n",
    "\n",
    "    # if not os.path.isdir(save_folder + os.sep + v[1]['ID']):\n",
    "    return fore_image, back_image, conv_hull, img[conv_hull], img[conv_hull==False]\n",
    "\n",
    "\n",
    "\n",
    "# def vol(v, sample_size, kk,outi_folder, ch_flag):\n",
    "#     switcher={\n",
    "#             'Mean': mean,\n",
    "#             'Range': rang,\n",
    "#             'Variance': variance,\n",
    "#             'CV': percent_coefficient_variation,\n",
    "#             'CPP': contrast_per_pixle,\n",
    "#             'PSNR': fpsnr,\n",
    "#             'SNR1': snr1,\n",
    "#             'SNR2': snr2,\n",
    "#             'SNR3': snr3,\n",
    "#             'SNR4': snr4,\n",
    "#             'CNR': cnr,\n",
    "#             'CVP': cvp,\n",
    "#             'CJV': cjv,\n",
    "#             'EFC': efc,\n",
    "#             'FBER': fber,\n",
    "#             }\n",
    "#     func=switcher.get(kk)\n",
    "#     M = []\n",
    "#     for i in range(1, len(v[0]), sample_size):\n",
    "#         I = v[0][i]\n",
    "# #        I = I - np.min(I)  # for CT\n",
    "#         F, B, c, f, b = foreground(I,outi_folder,v,i, ch_flag)\n",
    "#         if np.std(F) == 0:  # whole zero slice, no measure computing\n",
    "#             continue\n",
    "#         measure = func(F, B, c, f, b)\n",
    "#         if np.isnan(measure) or np.isinf(measure):\n",
    "#             continue\n",
    "#             # measure = 0\n",
    "#         # To do (add something)\n",
    "#         M.append(measure)\n",
    "#     return np.mean(M)\n",
    "\n",
    "\n",
    "# def foreground(img,save_folder,v,inumber, ch_flag):\n",
    "#     try:\n",
    "#         h = ex.equalize_hist(img[:,:])*255\n",
    "#         oi = np.zeros_like(img, dtype=np.uint16)\n",
    "#         oi[(img > threshold_otsu(img)) == True] = 1\n",
    "#         oh = np.zeros_like(img, dtype=np.uint16)\n",
    "#         oh[(h > threshold_otsu(h)) == True] = 1\n",
    "#         nm = img.shape[0] * img.shape[1]\n",
    "#         w1 = np.sum(oi)/(nm)\n",
    "#         w2 = np.sum(oh)/(nm)\n",
    "#         ots = np.zeros_like(img, dtype=np.uint16)\n",
    "#         new =( w1 * img) + (w2 * h)\n",
    "#         ots[(new > threshold_otsu(new)) == True] = 1\n",
    "#         if ch_flag == 'True':\n",
    "#             conv_hull = convex_hull_object(ots)\n",
    "#         elif ch_flag == 'False':\n",
    "#             conv_hull = convex_hull_image(ots)\n",
    "#         conv_hull = convex_hull_image(ots)\n",
    "#         ch = np.multiply(conv_hull, 1)\n",
    "#         fore_image = ch * img\n",
    "#         back_image = (1 - ch) * img\n",
    "#     except Exception:\n",
    "#         fore_image = img.copy()\n",
    "#         back_image = np.zeros_like(img, dtype=np.uint16)\n",
    "#         conv_hull = np.zeros_like(img, dtype=np.uint16)\n",
    "#         ch = np.multiply(conv_hull, 1)\n",
    "\n",
    "#     # if not os.path.isdir(save_folder + os.sep + v[1]['ID']):\n",
    "#     if '_foreground_masks' in save_folder + os.sep + v[1]['ID']:\n",
    "#         plt.imsave(save_folder + os.sep + v[1]['ID'] +'(%d).png' % int(inumber+1), scipy.ndimage.rotate(ch,0), cmap = cm.Greys_r)\n",
    "#     return fore_image, back_image, conv_hull, img[conv_hull], img[conv_hull==False]\n",
    "\n",
    "def mean(F, B, c, f, b):\n",
    "    return np.nanmean(f)\n",
    "\n",
    "def rang(F, B, c, f, b):\n",
    "    return np.ptp(f)\n",
    "\n",
    "def variance(F, B, c, f, b):\n",
    "    return np.nanvar(f)\n",
    "\n",
    "def percent_coefficient_variation(F, B, c, f, b):\n",
    "    return (np.nanstd(f)/np.nanmean(f))*100\n",
    "\n",
    "def contrast_per_pixle(F, B, c, f, b):\n",
    "    filt = np.array([[ -1/8, -1/8, -1/8],[-1/8, 1, -1/8],[ -1/8, -1/8,  -1/8]])\n",
    "    I_hat = conv2(F, filt, mode='same')\n",
    "    return np.nanmean(I_hat)\n",
    "\n",
    "def psnr(img1, img2):\n",
    "    mse = np.square(np.subtract(img1, img2)).mean()\n",
    "    return 20 * np.log10(np.nanmax(img1) / np.sqrt(mse))\n",
    "\n",
    "def fpsnr(F, B, c, f, b):\n",
    "    I_hat = median(F/np.max(F), square(5))\n",
    "    return psnr(F, I_hat)\n",
    "\n",
    "def snr1(F, B, c, f, b):\n",
    "    return np.nanstd(f) / np.nanstd(b)\n",
    "\n",
    "def patch(img, patch_size):\n",
    "    h = int(np.floor(patch_size / 2))\n",
    "    # U = pad(img, pad_width=h, mode='constant')\n",
    "    U = np.pad(img, pad_width=5, mode='constant')\n",
    "    [a,b]  = np.where(img == np.max(img))\n",
    "    a = a[0]\n",
    "    b = b[0]\n",
    "    return U[a:a+2*h+1,b:b+2*h+1]\n",
    "\n",
    "def snr2(F, B, c, f, b):\n",
    "    fore_patch = patch(F, 5)\n",
    "    return np.nanmean(fore_patch) / np.nanstd(b)\n",
    "\n",
    "def snr3(F, B, c, f, b):\n",
    "    fore_patch = patch(F, 5)\n",
    "    return np.nanmean(fore_patch)/np.nanstd(fore_patch - np.nanmean(fore_patch))\n",
    "\n",
    "def snr4(F, B, c, f, b):\n",
    "    fore_patch = patch(F, 5)\n",
    "    back_patch = patch(B, 5)\n",
    "    return np.nanmean(fore_patch) / np.nanstd(back_patch)\n",
    "\n",
    "def cnr(F, B, c, f, b):\n",
    "    fore_patch = patch(F, 5)\n",
    "    back_patch = patch(B, 5)\n",
    "    return np.nanmean(fore_patch-back_patch) / np.nanstd(back_patch)\n",
    "\n",
    "def cvp(F, B, c, f, b):\n",
    "    fore_patch = patch(F, 5)\n",
    "    return np.nanstd(fore_patch) / np.nanmean(fore_patch)\n",
    "\n",
    "def cjv(F, B, c, f, b):\n",
    "    return (np.nanstd(f) + np.nanstd(b)) / abs(np.nanmean(f) - np.nanmean(b))\n",
    "\n",
    "def efc(F, B, c, f, b):\n",
    "    n_vox = F.shape[0] * F.shape[1]\n",
    "    efc_max = 1.0 * n_vox * (1.0 / np.sqrt(n_vox)) * \\\n",
    "        np.log(1.0 / np.sqrt(n_vox))\n",
    "    cc = (F**2).sum()\n",
    "    b_max = np.sqrt(abs(cc))\n",
    "    return float((1.0 / abs(efc_max)) * np.sum(\n",
    "        (F / b_max) * np.log((F + 1e16) / b_max)))\n",
    "\n",
    "def fber(F, B, c, f, b):\n",
    "    fg_mu = np.nanmedian(np.abs(f) ** 2)\n",
    "    bg_mu = np.nanmedian(np.abs(b) ** 2)\n",
    "    if bg_mu < 1.0e-3:\n",
    "        return 0\n",
    "    return float(fg_mu / bg_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54796,
     "status": "ok",
     "timestamp": 1696081297143,
     "user": {
      "displayName": "vani sri",
      "userId": "04310237964180536629"
     },
     "user_tz": -330
    },
    "id": "TlQGxFM4UVOB",
    "outputId": "f3c701ac-0569-473e-d9ac-7928bba7ba6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: medpy in c:\\anaconda\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\anaconda\\lib\\site-packages (from medpy) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\anaconda\\lib\\site-packages (from medpy) (1.20.3)\n",
      "Requirement already satisfied: SimpleITK>=1.1.0 in c:\\anaconda\\lib\\site-packages (from medpy) (2.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in c:\\anaconda\\lib\\site-packages (2.4.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\anaconda\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\anaconda\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\anaconda\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\anaconda\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.20.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: umap-learn in c:\\anaconda\\lib\\site-packages (0.5.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\anaconda\\lib\\site-packages (from umap-learn) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\anaconda\\lib\\site-packages (from umap-learn) (0.24.2)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\anaconda\\lib\\site-packages (from umap-learn) (1.7.1)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\anaconda\\lib\\site-packages (from umap-learn) (0.54.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\anaconda\\lib\\site-packages (from umap-learn) (0.5.10)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\lib\\site-packages (from umap-learn) (4.62.3)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in c:\\anaconda\\lib\\site-packages (from numba>=0.49->umap-learn) (0.37.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\lib\\site-packages (from numba>=0.49->umap-learn) (67.3.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\anaconda\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm->umap-learn) (0.4.4)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\lib\\site-packages (1.20.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\anaconda\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\anaconda\\lib\\site-packages (from scipy) (1.20.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\anaconda\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\anaconda\\lib\\site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\anaconda\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\anaconda\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\anaconda\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\anaconda\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\anaconda\\lib\\site-packages (0.18.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\anaconda\\lib\\site-packages (from scikit-image) (1.20.3)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\anaconda\\lib\\site-packages (from scikit-image) (1.7.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\anaconda\\lib\\site-packages (from scikit-image) (3.4.3)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\anaconda\\lib\\site-packages (from scikit-image) (2.6.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\anaconda\\lib\\site-packages (from scikit-image) (8.4.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\anaconda\\lib\\site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\anaconda\\lib\\site-packages (from scikit-image) (2021.7.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\anaconda\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\anaconda\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\anaconda\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\anaconda\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install medpy\n",
    "!pip install pydicom\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install umap-learn\n",
    "!pip install numpy\n",
    "!pip install scipy\n",
    "!pip install matplotlib\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CqtpoVQ5Pss7"
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "# import QCF\n",
    "import time\n",
    "from medpy.io import load    # for .mha, .nii, or .nii.gz files\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pydicom               # for .dcm files\n",
    "from itertools import accumulate\n",
    "import pandas as pd\n",
    "from scipy.cluster.vq import whiten\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import umap\n",
    "# import umap.umap_ as umap\n",
    "\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")    # remove all warnings like conversion thumbnails\n",
    "\n",
    "nfiledone = 0\n",
    "csv_report = None\n",
    "first = True\n",
    "headers = []\n",
    "\n",
    "\n",
    "def patient_name(root):\n",
    "    print('MRQy is starting....')\n",
    "    files = [os.path.join(dirpath,filename) for dirpath, _, filenames in os.walk(root)\n",
    "                for filename in filenames\n",
    "                if filename.endswith('.dcm')\n",
    "                or filename.endswith('.mha')\n",
    "                or filename.endswith('.nii')\n",
    "                or filename.endswith('.gz')\n",
    "                or filename.endswith('.mat')]\n",
    "    mats = [i for i in files if i.endswith('.mat')]\n",
    "    dicoms = [i for i in files if i.endswith('.dcm')]\n",
    "    mhas = [i for i in files\n",
    "            if i.endswith('.mha')\n",
    "            or i.endswith('.nii')\n",
    "            or i.endswith('.gz')]\n",
    "    mhas_subjects = [os.path.basename(scan)[:os.path.basename(scan).index('.')] for scan in mhas]\n",
    "    dicom_subjects = []\n",
    "    mat_subjects = [os.path.basename(scan)[:os.path.basename(scan).index('.')] for scan in mats]\n",
    "\n",
    "    if folders_flag == \"False\":\n",
    "        for i in dicoms:\n",
    "            dicom_subjects.append(pydicom.dcmread(i).PatientID)\n",
    "        duplicateFrequencies = {}\n",
    "        for i in dicom_subjects:\n",
    "            duplicateFrequencies[i] = dicom_subjects.count(i)\n",
    "\n",
    "        subjects_id = []\n",
    "        subjects_number = []\n",
    "        for i in range(len(duplicateFrequencies)):\n",
    "              subjects_id.append(list(duplicateFrequencies.items())[i][0])\n",
    "              subjects_number.append(list(duplicateFrequencies.items())[i][1])\n",
    "        ind = [0] + list(accumulate(subjects_number))\n",
    "        splits = [dicoms[ind[i]:ind[i+1]] for i in range(len(ind)-1)]\n",
    "    elif folders_flag == \"True\":\n",
    "        dicom_subjects = [d for d in os.listdir(root) if os.path.isdir(root + os.sep + d)]\n",
    "        subjects_number = []\n",
    "        for i in range(len(dicom_subjects)):\n",
    "            subjects_number.append(\n",
    "                len([os.path.join(dirpath,filename) for dirpath, _, filenames in os.walk(root + os.sep + dicom_subjects[i])\n",
    "            for filename in filenames\n",
    "            if filename.endswith('.dcm')]))\n",
    "        subjects_id  = dicom_subjects\n",
    "        ind = [0] + list(accumulate(subjects_number))\n",
    "        splits = [dicoms[ind[i]:ind[i+1]] for i in range(len(ind)-1)]\n",
    "\n",
    "\n",
    "    subjects = subjects_id + mhas_subjects + mat_subjects\n",
    "    print('The number of patients is {}'.format(len(subjects)))\n",
    "    return files, subjects, splits, mhas, mhas_subjects, mats, mat_subjects\n",
    "\n",
    "\n",
    "def volume_dicom(scans, name):\n",
    "    scans = scans[int(0.005 *len(scans)*(100 - middle_size)):int(0.005 *len(scans)*(100 + middle_size))]\n",
    "    inf = pydicom.dcmread(scans[0])\n",
    "    if hasattr(inf, 'MagneticFieldStrength'):\n",
    "        if inf.MagneticFieldStrength > 10:\n",
    "            inf.MagneticFieldStrength = inf.MagneticFieldStrength/10000\n",
    "    else:\n",
    "        inf.MagneticFieldStrength = ''\n",
    "\n",
    "    if hasattr(inf, 'Manufacturer') == False:\n",
    "        inf.Manufacturer = ''\n",
    "    if  hasattr(inf, 'RepetitionTime') == False:\n",
    "            inf.RepetitionTime = 0\n",
    "    if  hasattr(inf, 'EchoTime') == False:\n",
    "            inf.EchoTime = 0\n",
    "    if folders_flag == \"False\":\n",
    "        name_vale = inf.PatientID\n",
    "    elif folders_flag == \"True\":\n",
    "        name_vale = name\n",
    "\n",
    "    tags = {\n",
    "             'ID': name_vale,\n",
    "             'MFR': inf.Manufacturer,\n",
    "             'VRX': format(inf.PixelSpacing[0], '.2f'),\n",
    "             'VRY': format(inf.PixelSpacing[1], '.2f'),\n",
    "             'VRZ': format(inf.SliceThickness, '.2f'),\n",
    "             'MFS': inf.MagneticFieldStrength,\n",
    "             'ROWS': int(inf.Rows),\n",
    "             'COLS': int(inf.Columns),\n",
    "             # 'TR': format(inf.RepetitionTime, '.2f'),\n",
    "             'TR': inf.RepetitionTime,\n",
    "             # 'TE': format(inf.EchoTime, '.2f'),\n",
    "             'TE': inf.EchoTime,\n",
    "             'NUM': len(scans)\n",
    "    }\n",
    "    tag_values = []\n",
    "    slices = [pydicom.read_file(s) for s in scans]\n",
    "    slices.sort(key = lambda x: int(x.InstanceNumber))\n",
    "    # PL = pd.DataFrame([s.pixel_array for s in slices], columns=['images'])\n",
    "    # images = PL['images'].to_numpy().astype(np.int64)\n",
    "    images = np.stack([s.pixel_array for s in slices])\n",
    "    images = images.astype(np.int64)\n",
    "    return images, tags\n",
    "\n",
    "def volume_notdicom(scan, name):\n",
    "    image_data, image_header = load(scan)\n",
    "    images = [image_data[:,:,i] for i in range(np.shape(image_data)[2])]\n",
    "    return images, name, image_header\n",
    "\n",
    "\n",
    "def volume_mat(mat_scan, name):\n",
    "    v1 = loadmat(mat_scan)['vol']\n",
    "    tags = {'ID': name}\n",
    "    return v1, tags\n",
    "\n",
    "\n",
    "def saveThumbnails_dicom(v, output):\n",
    "    if save_masks_flag!='False':\n",
    "        ffolder = output + '_foreground_masks'\n",
    "        os.makedirs(ffolder + os.sep + v[1]['ID'])\n",
    "    elif save_masks_flag=='False':\n",
    "        ffolder = output\n",
    "    os.makedirs(output + os.sep + v[1]['ID'])\n",
    "    for i in range(0, len(v[0]), sample_size):\n",
    "        plt.imsave(output + os.sep + v[1]['ID'] + os.sep + v[1]['ID'] + '(%d).png' % i, v[0][i], cmap = cm.Greys_r)\n",
    "    print('The number of %d images are saved to %s' % (len(v[0]),output + os.sep + v[1]['ID']))\n",
    "    return ffolder + os.sep + v[1]['ID']\n",
    "\n",
    "def saveThumbnails_mat(v, output):\n",
    "    if save_masks_flag!='False':\n",
    "        ffolder = output + '_foreground_masks'\n",
    "        os.makedirs(ffolder + os.sep + v[1]['ID'])\n",
    "    elif save_masks_flag=='False':\n",
    "        ffolder = output\n",
    "    os.makedirs(output + os.sep + v[1]['ID'])\n",
    "    for i in range(np.shape(v[0])[2]):\n",
    "        plt.imsave(output + os.sep + v[1]['ID']+ os.sep + v[1]['ID'] + '(%d).png' % int(i+1), v[0][:,:,i], cmap = cm.Greys_r)\n",
    "    print('The number of %d images are saved to %s' % (np.shape(v[0])[2],output + os.sep + v[1]['ID']))\n",
    "    return ffolder + os.sep + v[1]['ID']\n",
    "\n",
    "\n",
    "def saveThumbnails_nondicom(v, output):\n",
    "    os.makedirs(output + os.sep + v[1])\n",
    "    for i in range(len(v[0])):\n",
    "        plt.imsave(output + os.sep + v[1] + os.sep + v[1] + '(%d).png' % int(i+1), scipy.ndimage.rotate(v[0][i],270), cmap = cm.Greys_r)\n",
    "        # print('image number %d out of %d is saved to %s' % (int(i+1), len(v[0]),output + os.sep + v[1]))\n",
    "    print('The number of %d images are saved to %s' % (len(v[0]),output + os.sep + v[1]))\n",
    "\n",
    "def worker_callback(s,fname_outdir):\n",
    "    global csv_report, first, nfiledone\n",
    "    if nfiledone  == 0:\n",
    "        csv_report = open(fname_outdir + os.sep + \"results\" + \".tsv\" , overwrite_flag, buffering=1)\n",
    "        first = True\n",
    "\n",
    "    if first and overwrite_flag == \"w\":\n",
    "        first = False\n",
    "        csv_report.write(\"\\n\".join([\"#\" + s for s in headers])+\"\\n\")\n",
    "        csv_report.write(\"#dataset:\"+\"\\t\".join(s[\"output\"])+\"\\n\")\n",
    "\n",
    "    csv_report.write(\"\\t\".join([str(s[field]) for field in s[\"output\"]])+\"\\n\")\n",
    "    csv_report.flush()\n",
    "    nfiledone += 1\n",
    "    print('The results are updated.')\n",
    "\n",
    "\n",
    "\n",
    "def tsv_to_dataframe(tsvfileaddress):\n",
    "    return pd.read_csv(tsvfileaddress, sep='\\t', skiprows=2, header=0)\n",
    "\n",
    "\n",
    "def data_whitening(dframe):\n",
    "    dframe = dframe.fillna('N/A')\n",
    "    df = dframe.copy()\n",
    "    df = df.select_dtypes(exclude=['object'])\n",
    "    ds = whiten(df)\n",
    "    return ds\n",
    "\n",
    "def tsne_umap(dataframe, per):\n",
    "    ds = data_whitening(dataframe)\n",
    "    ds_umap = ds.copy()\n",
    "    tsne = TSNE(n_components=2, random_state=0, perplexity = per)\n",
    "    tsne_obj = tsne.fit_transform(ds)\n",
    "    dataframe['x'] = tsne_obj[:,0].astype(float)\n",
    "    dataframe['y'] = tsne_obj[:,1].astype(float)\n",
    "    reducer = umap.UMAP()\n",
    "    embedding = reducer.fit_transform(ds_umap)\n",
    "    dataframe['u'] = embedding[:,0]\n",
    "    dataframe['v'] = embedding[:,1]\n",
    "\n",
    "\n",
    "def cleanup(final_address, per):\n",
    "    df = tsv_to_dataframe(final_address)\n",
    "    tsne_umap(df, per)\n",
    "    hf = pd.read_csv(final_address, sep='\\t',  nrows=1)\n",
    "    hf.to_csv(final_address, index = None, header=True, sep = '\\t', mode = 'w')\n",
    "    df.to_csv(final_address, index = None, header=True, sep = '\\t', mode = 'a')\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_msg_box(msg, indent=1, width=None, title=None):\n",
    "    lines = msg.split('\\n')\n",
    "    space = \" \" * indent\n",
    "    if not width:\n",
    "        width = max(map(len, lines))\n",
    "    box = f'╔{\"═\" * (width + indent * 2)}╗\\n'\n",
    "    if title:\n",
    "        box += f'║{space}{title:<{width}}{space}║\\n'\n",
    "        box += f'║{space}{\"-\" * len(title):<{width}}{space}║\\n'\n",
    "    box += ''.join([f'║{space}{line:<{width}}{space}║\\n' for line in lines])\n",
    "    box += f'╚{\"═\" * (width + indent * 2)}╝'\n",
    "    print(box)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wZ_t4KCWP04V"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15332/3037056191.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputdir\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mfolders_flag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"False\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0msave_masks_flag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"False\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "headers.append(f\"start_time:\\t{datetime.datetime.now()}\")\n",
    "output_folder_name = ''\n",
    "inputdir = ''\n",
    "r = 0\n",
    "s = 0\n",
    "b = 1\n",
    "u = 100\n",
    "t = 0\n",
    "c = 0\n",
    "\n",
    "root = inputdir[0]\n",
    "folders_flag = \"False\"\n",
    "save_masks_flag = \"False\"\n",
    "sample_size = 1\n",
    "middle_size = 100\n",
    "ch_flag = \"False\"\n",
    "\n",
    "print(os.getcwd())\n",
    "#print_forlder_note = os.getcwd() + os.sep + 'UserInterface'\n",
    "# print_forlder_note = os.path.abspath(os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)), os.pardir))+ os.sep + 'UserInterface'\n",
    "\n",
    "# print(print_forlder_note)\n",
    "fname_outdir = \"/content/drive/MyDrive/MRI_Quality_Assessment/Output\"\n",
    "\n",
    "overwrite_flag = \"w\"\n",
    "headers.append(f\"outdir:\\t{os.path.realpath(fname_outdir)}\")\n",
    "patients, names, dicom_spil, nondicom_spli, nondicom_names, mat_spli, mat_names = patient_name(root)\n",
    "\n",
    "for j in range(len(dicom_spil)):\n",
    "    v = volume_dicom(dicom_spil[j], names[j])\n",
    "    folder_foregrounds = saveThumbnails_dicom(v,fname_outdir)\n",
    "    s = BaseVolume_dicom(fname_outdir, v,j+1,folder_foregrounds, sample_size, ch_flag)\n",
    "    worker_callback(s,fname_outdir)\n",
    "dicom_flag = False\n",
    "\n",
    "address = fname_outdir + os.sep + \"results\" + \".tsv\"\n",
    "\n",
    "if len(names) < 6:\n",
    "    print('Skipped the t-SNE and UMAP computation because of insufficient data. The UMAP and t-SNE process need at least 6 input data.')\n",
    "    df = tsv_to_dataframe(address)\n",
    "else:\n",
    "    df = cleanup(address, 30)\n",
    "    df = df.drop(['Name of Images'], axis=1)\n",
    "    df = df.rename(columns={\"#dataset:Patient\": \"Patient\",\n",
    "                            \"x\":\"TSNEX\",\"y\":\"TSNEY\", \"u\":\"UMAPX\", \"v\":\"UMAPY\" })\n",
    "    df = df.fillna('N/A')\n",
    "\n",
    "df.to_csv(fname_outdir + os.sep +'IQM.csv',index=False)\n",
    "print(\"The IQMs data are saved in the {} file. \".format(fname_outdir + os.sep + \"IQM.csv\"))\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMYBfRWoO1odPe7b/auOVdh",
   "mount_file_id": "1eR11gV5WO-WvAP-A3Qem60-EKHPZ6kBu",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
